{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa0258e-3ee8-49cf-af47-9691308b55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below and run the installations\n",
    "#!pip install torch\n",
    "#!pip install torchvision\n",
    "#!pip install opencv-python\n",
    "#!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28851f5e-a9d1-476a-b772-b285589c7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7da7cb52-1bc0-4092-8292-99f86d311402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 112.30059990516075\n",
      "Standard Deviation: 85.98406628052774\n"
     ]
    }
   ],
   "source": [
    "# Calculating the mean and standard deviation of the data set\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def load_images_from_folder(folder, target_size=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, target_size)\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "def compute_mean_std(images):\n",
    "    stacked_images = np.stack(images, axis=0)\n",
    "    mean = np.mean(stacked_images)\n",
    "    std = np.std(stacked_images)\n",
    "    return mean, std\n",
    "\n",
    "folder_path = 'C:\\\\Users\\\\Khomp\\Desktop\\\\Projetos SBC 2025\\\\ResNet50\\\\Health-projects\\\\Chest_Xray-classification\\\\checandoMEDIAeSD'\n",
    "images = load_images_from_folder(folder_path)\n",
    "mean, std = compute_mean_std(images)\n",
    "\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Standard Deviation: {std}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8473b06-9084-4178-bbc3-17e0ffc167f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining data transformations for grayscale images with the computed mean and std\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([112.3006 / 255], [85.9841 / 255])  # Normalize using the computed mean and std\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([112.3006 / 255], [85.9841 / 255])  # Normalize using the computed mean and std\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c784e3b9-6557-4bb6-aed5-bbeb2b358d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the data directory\n",
    "data_dir = 'dataset'\n",
    "\n",
    "# Creating data loaders\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "#image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "989eb9de-7e22-4e9f-8375-3e8ae69f9c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 91, 'val': 13}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['healthy', 'tuberculosis']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1f40f-b5b6-4e8e-97b7-adff47a48d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet-18 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers except the final classification layer\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" in name:  # Unfreeze the final classification layer\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Use all parameters\n",
    "\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
